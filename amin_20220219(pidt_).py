# -*- coding: utf-8 -*-
"""Amin-20220219(PIDT ).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TXnsGkzFwAl0arI_V1q4GdRdmV0UZFGn

[Paper 2 Link](https://sciendo-parsed.s3.eu-central-1.amazonaws.com/647387ff4e662f30ba541057/10.2478_slgr-2013-0045.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIA6AP2G7AKP2BFFZZU%2F20250503%2Feu-central-1%2Fs3%2Faws4_request&X-Amz-Date=20250503T170051Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEFkaDGV1LWNlbnRyYWwtMSJHMEUCIQChLRp8J8Ja0V2j8fbwS4%2FqGR%2Fnr0JdL%2FqESJZpktklkQIgZufNUy4%2Bd8xPPqWKCHLjBW45HeicuDLvc%2BumIP%2FAGjIqxgUI8v%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARACGgw5NjMxMzQyODk5NDAiDEUXmWkgNtE38y9twyqaBT6pz6gfhDCcWSn4OBuZPdDvW9IB9pnHpcpnQdgGVUBFae1fDw5kiP4dqkDwR0YPfbEP%2BHGsw7NbV8X4zm1JfzzhNFPgXVTPIZtQnUO4%2B1nUSZubpZ5RICkH7TpvuFUDDHmMJpKLOYuZw6ZvaGXOmqgYqL%2F3z3eDsobeDpI9eTvyzld99KJy13alzM4o1KIlB9inX1tWClr%2FDKOKSbadXjkt%2BRSnQWVxnWPEmgFZQFnIJZCEVQ3wEB%2Bnb4f1lgcae4lV5UKpfC491DUXmZLbog4tVyplpEfkBFl6Z5smNDj%2FCfVFpFsUBl6Y5KJbyTVOpa4%2Fs8%2BqGv9PKOrc7VcqxTqznzMYSPVkQNq608jfelphOULvvrec9mJ9PBiS5hCaRBxiiEw3nTv6sLuDlQnXvSpWtGg0mg7JwEg9qOAdPwukdyijE5H8c%2BuVK6SvTI4tf6I9fpQO9U7%2B%2BIgbCgReJdyLmLjGSyVPYjwV0S5tzCfGsKa4l0MXXuM1HFXpzWmHw%2BPfUndINQMBawY%2FfYzTd3s%2Bs5SAF3Cc5Yf%2FBL3FZwH9tJXjAi3A5icZGuu1YBagNMt76tXHh0d4C%2BY9vum8ey0hqpRfSdXZsR5yq7TKPnFkBXblhhWy2OnRHqAZOooy2KSxGgN9qVRgUH11P4xGVvPzsZtYP3TarTv%2BWkV2CTBTTAGjf21w85lgyPmVH5eY4%2F6YBYU1LP5m%2BMj5akWSVnOupdG2kUYxCxdK7qnxK02gbx6g4Kq40I83KagI7Um8t%2F0KMPyctml8nC9ildPxn6mo%2F5ErSKk307vQbl2pcLOyWzcScAt5N%2FJFBxNZFFLPzSGYksUZGyqT7PD4zoH0ICqi1MazbEvC286Bx%2BQbNAU9CsTaFWvMrQsZETCciNnABjqxAV%2Bl5SXAcKAIDtOGJDEIa6WuNMUrwZ4YGUN5QEXqiXIXtLhH9wjuzWbsAFj9alU4gaOgSoqzuUq0yCCUla0BuM6dlueeR0tLZi1BQrOOHBuNKZ8shh%2BSJZ%2B9UaTHICTo0tzDJeJy7WCxQU0qItzVTnR%2BFTeKTeQSsH43bPwdICs9Z4fYADHQfgXOHzG%2B4sylSK5rnWdxd%2FKmoqYd1WLGIPJd9WMvdzNW7KLIXR54MA4u5g%3D%3D&X-Amz-Signature=07fc1e5d3ee4b9e1d08b69e2350c31ccba1605837a0e02cecd1f590adc801e56&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObject)



Model: Bayesian classifiers (like Parzen) combined with decision trees
"""

!pip install ucimlrepo

!pip install scikit-learn matplotlib seaborn shap lime

from lime import lime_tabular

import shap
import lime
import numpy as np
import pandas as pd
import seaborn as sns
import lime.lime_tabular
from sklearn.svm import SVC
from lime import lime_tabular
import matplotlib.pyplot as plt
from ucimlrepo import fetch_ucirepo
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.datasets import load_breast_cancer
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder
from lime.lime_tabular import LimeTabularExplainer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import mutual_info_regression
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc
from sklearn.model_selection import train_test_split, learning_curve, validation_curve, cross_val_score
from sklearn.metrics import precision_recall_curve, average_precision_score, PrecisionRecallDisplay
from sklearn.feature_selection import (mutual_info_regression, chi2, f_classif, SelectKBest, VarianceThreshold)
from sklearn.metrics import (accuracy_score, confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error, r2_score)

"""# **1) Data Overview**"""

# fetch dataset
breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)

# The Data into DataFrame
df = pd.concat([
    breast_cancer_wisconsin_diagnostic.data.features,
    breast_cancer_wisconsin_diagnostic.data.targets
], axis=1)

df.head()

# Number of Rows and Number of Columns
Rows, Cols = df.shape
print("Number of Row in Data = ", Rows)
print("Number of Columns in Data = ", Cols)

# Columns Names
df.columns

df.info()

# Verify data types
df.dtypes

"""# **2) Preprocessing & Cleaning**"""

# Handling Null Values
df.isnull().sum()

# Check Duplicates
print(df.duplicated().sum())

"""## **Handling Outliers**"""

for col in df.columns:
  if ((df[col].dtype) == "int64") or ((df[col].dtype) == "float64"):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    # Define lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Calculate mean (excluding outliers)
    mean_value = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)][col].mean()

    # Replace outliers with mean
    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), mean_value, df[col])

count = 0

for col in df.columns:
  if count == 30:
    break
  # Create boxplot
  plt.boxplot(df[col])

  # Add labels
  plt.title("Boxplot for " + col + " column")
  plt.ylabel("Values")

  # Show plot
  plt.show()

  count = count + 1

"""# **3) EDA**

## A) Univariate Analysis
"""

# Statistics
df.describe()

# Target Value Counts
target_df = pd.Series(df["Diagnosis"], name='target')
target_df.value_counts(normalize=True)

# Distrubtion Of Featuers

for col in df.columns:
  if ((df[col].dtype) == "int64") or ((df[col].dtype) == "float64"):
    # Plot histogram
    plt.hist(df[col], bins=30, color='blue', edgecolor='black')

    # Add labels
    plt.title("Histogram for " + col + " column")
    plt.xlabel("Value")
    plt.ylabel("Frequency")

    # Show plot
    plt.show()

# Target Value Distrubtion

# Plot histogram
plt.hist(df["Diagnosis"], bins=30, color='blue', edgecolor='black')

# Add labels
plt.title("Diagnosis Histogram")
plt.xlabel("Value")
plt.ylabel("Frequency")

# Distrubtion Of Featuers

count = 0
for col in df.columns:

  if count == 30:
    break
  sns.kdeplot(df[col], shade=True)
  plt.title('KDE Plot for ' + col + ' column')
  plt.show()
  count = count + 1

# Skewness & Kurtosis
count = 0
for col in df.columns:
  if count == 30:
    break
  print("Skewness for " , col , " column: ", df[col].skew())
  print("Kurtosis for" , col, "column: " , df[col].kurt())
  print("\n")
  count = count + 1

"""## B) Bivariate/Multivariate Analysis"""

# Drop object column
df_numeric = df.drop(columns=['Diagnosis'])

# Compute correlation matrix
corr_matrix = df_numeric.corr()

# Plot heatmap
plt.figure(figsize=(40, 20))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)

# Show plot
plt.title("Correlation Heatmap (Integer Columns Only)")
plt.show()

# Relationship between radius1 and texture1 column
sns.scatterplot(x='radius1', y='texture1', hue=df["Diagnosis"], data=df)
plt.title('radius1 vs texture1')
plt.show()

# Boxplot by Target

count = 0

for col in df.columns:
  if count == 30:
    break

  sns.boxplot(x='Diagnosis', y=col, data=df)
  plt.title('Boxplot Between Diagnosis and ' + col)
  plt.show()

  count = count + 1

"""# **4) Feature Engineering and Selection**"""

X = df.drop('Diagnosis', axis=1)
y = df['Diagnosis']

y = np.where(y == 'M', 1, 0)

# Features Scaling, Normalization
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

"""## Remove High Correlated Features"""

# Use variance inflation factor to identify any significant multi-collinearity
def calc_vif(df):
    vif = pd.DataFrame()
    vif["variables"] = df_numeric.columns
    vif["VIF"] = [variance_inflation_factor(df_numeric.values, i) for i in range(df_numeric.shape[1])]
    return(vif)

calc_vif(df_numeric)

"""Remove High Correlated Features: (radius1, perimeter1, fractal_dimension1)

## Feature Importance using Mutual Information
"""

feature_names = [col for col in df.columns if col != "Diagnosis"]

# Encoding the Target
le = LabelEncoder()
y_encoded = le.fit_transform(y)

mi_scores = mutual_info_classif(X, y_encoded)
mi_scores = pd.Series(mi_scores, index=feature_names)
mi_scores.sort_values(ascending=False, inplace=True)

# Plot Information Gain
plt.figure(figsize=(10, 6))
mi_scores.plot(kind="bar", color="teal")
plt.title("Information Gain (Mutual Information)")
plt.xlabel("Features")
plt.ylabel("Mutual Information Score")
plt.show()

"""## Feature Selection using ANOVA"""

# ANOVA (F-test)
f_scores, _ = f_classif(X, y)  # ANOVA F-test
f_scores = pd.Series(f_scores, index=feature_names)
f_scores.sort_values(ascending=False, inplace=True)

# Plot ANOVA F-scores
plt.figure(figsize=(10, 6))
f_scores.plot(kind="bar", color="red")
plt.title("ANOVA F-scores")
plt.xlabel("Features")
plt.ylabel("F-score")
plt.show()

"""There is High relationship Between (perimeter3, cnocave_points1, radius3) features and the target. and the Relation between (texture2, smoothness2, symmetry2) is very low

## Feature Selection using Variance Threshold
"""

# Variance Threshold
variance_threshold = VarianceThreshold(threshold=0.1)  # Remove low-variance features
X_variance_selected = variance_threshold.fit_transform(X)

# Get selected features
selected_features = variance_threshold.get_support(indices=True)
print("Selected Features (Variance Threshold):", [feature_names[i] for i in selected_features])

# Remove High Correlated Features, low-variance features and low relationship features
df = df.drop(['radius1', 'perimeter1', 'fractal_dimension1'], axis=1)
df_numeric = df_numeric.drop(['radius1', 'perimeter1', 'fractal_dimension1'], axis=1)

"""##**model 3 implementation**"""

# # the PIDT (Parameterised Impurity Decision Tree)
# class PIDTDecisionTree(DecisionTreeClassifier):
#     def __init__(self, impurity_type='entropy', alpha=1.0, beta=None, **kwargs):
#         super().__init__(**kwargs)
#         self.impurity_type = impurity_type
#         self.alpha = alpha
#         self.beta = beta

#     def _impurity(self, y):
#         """Compute the impurity of a node based on the selected impurity measure."""
#         p = np.bincount(y) / len(y)  # Probability distribution of classes
#         if self.impurity_type == 'entropy':
#             return parameterized_entropy(p, self.alpha)
#         elif self.impurity_type == 'gini':
#             return parameterized_gini(p, self.alpha)
#         elif self.impurity_type == 'renyi':
#             return parameterized_renyi(p, self.alpha)
#         elif self.impurity_type == 'tsallis':
#             return parameterized_tsallis(p, self.alpha)
#         else:
#             raise ValueError("Invalid impurity type")

#     def _split_impurity(self, X, y, feature, threshold):
#         """Compute the impurity after a split on the given feature and threshold."""
#         left_mask = X[:, feature] <= threshold
#         right_mask = ~left_mask

#         left_y = y[left_mask]
#         right_y = y[right_mask]

#         left_impurity = self._impurity(left_y)
#         right_impurity = self._impurity(right_y)

#         return left_impurity, right_impurity

#     def fit(self, X, y):
#         """Fit the decision tree to the data."""
#         # This would be the custom implementation of the decision tree learning process,
#         # which should use the parameterized impurity measures in the splitting criterion.
#         super().fit(X, y)  # For simplicity, using the base DecisionTreeClassifier's fit method

#     def predict(self, X):
#         """Predict the class labels for the input data."""
#         return super().predict(X)

def parameterized_entropy(D, alpha=1.0):
    # Formula for parameterized entropy
    prob = np.array([np.sum(D == i) / len(D) for i in np.unique(D)])
    return -np.sum(prob * np.log(prob) ** alpha)

def parameterized_gini(D, alpha=1.0):
    # Formula for parameterized Gini index
    prob = np.array([np.sum(D == i) / len(D) for i in np.unique(D)])
    return 1 - np.sum(prob ** 2) ** alpha

def parameterized_tsallis(D, alpha=1.0):
    # Formula for parameterized Tsallis entropy
    prob = np.array([np.sum(D == i) / len(D) for i in np.unique(D)])
    return 1 - np.sum(prob ** alpha) / (alpha - 1)

def parameterized_renyi(D, alpha=1.0):
    # Formula for parameterized Renyi entropy
    prob = np.array([np.sum(D == i) / len(D) for i in np.unique(D)])
    return 1 / (1 - alpha) * np.log(np.sum(prob ** alpha))

# Implementing a simplified decision tree based on parameterized impurity measures

class PIDT:
    def __init__(self, impurity_function=parameterized_entropy, max_depth=10, alpha=1.0, beta=1.0):
        self.impurity_function = impurity_function
        self.max_depth = max_depth
        self.alpha = alpha
        self.beta = beta
        self.tree = None

    def fit(self, X, y):
        self.tree = self._build_tree(X, y, depth=0)

    def _build_tree(self, X, y, depth):
        # Stop if max depth is reached or only one class remains
        if depth >= self.max_depth or len(np.unique(y)) == 1:
            return np.bincount(y) / len(y)  # Return class probabilities (frequency of 0 or 1)

        best_impurity = float('inf')
        best_split = None
        best_left_y = None
        best_right_y = None
        best_left_X = None
        best_right_X = None

        # Iterate through features to find the best split
        for feature in range(X.shape[1]):
            thresholds = np.unique(X[:, feature])
            for threshold in thresholds:
                left_mask = X[:, feature] <= threshold
                right_mask = ~left_mask
                left_y = y[left_mask]
                right_y = y[right_mask]

                # Calculate impurity for left and right nodes
                left_impurity = self.impurity_function(left_y, alpha=self.alpha)
                right_impurity = self.impurity_function(right_y, alpha=self.alpha)

                # Total impurity
                impurity = (len(left_y) * left_impurity + len(right_y) * right_impurity) / len(y)

                if impurity < best_impurity:
                    best_impurity = impurity
                    best_split = (feature, threshold)
                    best_left_y = left_y
                    best_right_y = right_y
                    best_left_X = X[left_mask]
                    best_right_X = X[right_mask]

        if best_split is None:
            return np.bincount(y) / len(y)  # Return class probabilities at leaf nodes

        left_tree = self._build_tree(best_left_X, best_left_y, depth + 1)
        right_tree = self._build_tree(best_right_X, best_right_y, depth + 1)

        return {'feature': best_split[0], 'threshold': best_split[1], 'left': left_tree, 'right': right_tree}

    def predict(self, X):
        return np.array([self._predict_single(x, self.tree) for x in X])

    def _predict_single(self, x, tree):
        if isinstance(tree, dict):
            feature = tree['feature']
            threshold = tree['threshold']
            if x[feature] <= threshold:
                return self._predict_single(x, tree['left'])
            else:
                return self._predict_single(x, tree['right'])
        else:
            # Return class 1 if the probability is greater than 0.5, otherwise class 0
            return 1 if tree[1] > tree[0] else 0

    def predict_proba(self, X):
        return np.array([self._predict_proba_single(x, self.tree) for x in X])

    def _predict_proba_single(self, x, tree):
        if isinstance(tree, dict):
            feature = tree['feature']
            threshold = tree['threshold']
            if x[feature] <= threshold:
                return self._predict_proba_single(x, tree['left'])
            else:
                return self._predict_proba_single(x, tree['right'])
        else:
            # Return the probability of class 1 and class 0
            return tree

# Train the model
pidt_model = PIDT(impurity_function=parameterized_entropy, alpha=0.5, max_depth=10)
pidt_model.fit(X_train, y_train)

y_pred = pidt_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.4f}")

explainer = lime_tabular.LimeTabularExplainer(X_train, mode="classification", training_labels=y_train, feature_names=breast_cancer_wisconsin_diagnostic.data.columns)
i = 0  # Selecting the first test sample for explanation
explanation = explainer.explain_instance(X_test[i], pidt_model.predict_proba, num_features=5)

# LIME Visualization
explanation.show_in_notebook(show_table=True, show_all=False)

# SHAP: SHapley Additive exPlanations
explainer_shap = shap.KernelExplainer(pidt_model.predict, X_train)
shap_values = explainer_shap.shap_values(X_test)

shap_values.shape



# SHAP Summary Plot
shap.summary_plot(shap_values[1], X_test, feature_names=breast_cancer_wisconsin_diagnostic.data.columns)

# Learning Curve: Plot the learning curve
train_sizes, train_scores, test_scores = learning_curve(pidt_model, X, y, train_sizes=np.linspace(0.1, 1.0, 5), cv=5)

plt.figure(figsize=(8, 6))
plt.plot(train_sizes, np.mean(train_scores, axis=1), label="Training score")
plt.plot(train_sizes, np.mean(test_scores, axis=1), label="Cross-validation score")
plt.xlabel("Training Size")
plt.ylabel("Score")
plt.title("Learning Curve")
plt.legend()
plt.show()

# Validation Curve: Plot the validation curve for 'max_depth' as an example hyperparameter
param_range = np.arange(1, 21)
train_scores, test_scores = validation_curve(pidt_model, X, y, param_name="max_depth", param_range=param_range, cv=5)

plt.figure(figsize=(8, 6))
plt.plot(param_range, np.mean(train_scores, axis=1), label="Training score")
plt.plot(param_range, np.mean(test_scores, axis=1), label="Validation score")
plt.xlabel("Max Depth")
plt.ylabel("Score")
plt.title("Validation Curve for Max Depth Hyperparameter")
plt.legend()
plt.show()