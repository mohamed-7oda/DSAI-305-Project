# -*- coding: utf-8 -*-
"""Amin-20220219(MLIT).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dVjFmA-VnBUkBr4IORLkO-0OersISgjf

Paper 1 Link: https://iopscience.iop.org/article/10.1088/1757-899X/495/1/012033/pdf

Model: SVM-LDA


Paper 2 Link: https://opus.lib.uts.edu.au/bitstream/10453/17924/1/2010004689.pdf
"""

!pip install ucimlrepo

!pip install scikit-learn matplotlib seaborn shap lime



import shap
import lime
import numpy as np
import pandas as pd
import seaborn as sns
import lime.lime_tabular
from sklearn.svm import SVC
import matplotlib.pyplot as plt
from ucimlrepo import fetch_ucirepo
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import learning_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import mutual_info_regression
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc
from sklearn.metrics import precision_recall_curve, average_precision_score, PrecisionRecallDisplay
from sklearn.feature_selection import (mutual_info_regression, chi2, f_classif, SelectKBest, VarianceThreshold)
from sklearn.metrics import (accuracy_score, confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error, r2_score)

# fetch dataset
breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)

# The Data into DataFrame
df = pd.concat([
    breast_cancer_wisconsin_diagnostic.data.features,
    breast_cancer_wisconsin_diagnostic.data.targets
], axis=1)

"""# **1) Data Overview**"""

df.head()

# Number of Rows and Number of Columns
Rows, Cols = df.shape
print("Number of Row in Data = ", Rows)
print("Number of Columns in Data = ", Cols)

# Columns Names
df.columns

df.info()

# Verify data types
df.dtypes

"""# **2) Preprocessing & Cleaning**"""

# Handling Null Values
df.isnull().sum()

# Check Duplicates
print(df.duplicated().sum())

"""## **Handling Outliers**"""

for col in df.columns:
  if ((df[col].dtype) == "int64") or ((df[col].dtype) == "float64"):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    # Define lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Calculate mean (excluding outliers)
    mean_value = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)][col].mean()

    # Replace outliers with mean
    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), mean_value, df[col])

count = 0

for col in df.columns:
  if count == 30:
    break
  # Create boxplot
  plt.boxplot(df[col])

  # Add labels
  plt.title("Boxplot for " + col + " column")
  plt.ylabel("Values")

  # Show plot
  plt.show()

  count = count + 1

"""# **3) EDA**

## A) Univariate Analysis
"""

# Statistics
df.describe()

# Target Value Counts
target_df = pd.Series(df["Diagnosis"], name='target')
target_df.value_counts(normalize=True)

# Distrubtion Of Featuers

for col in df.columns:
  if ((df[col].dtype) == "int64") or ((df[col].dtype) == "float64"):
    # Plot histogram
    plt.hist(df[col], bins=30, color='blue', edgecolor='black')

    # Add labels
    plt.title("Histogram for " + col + " column")
    plt.xlabel("Value")
    plt.ylabel("Frequency")

    # Show plot
    plt.show()

# Target Value Distrubtion

# Plot histogram
plt.hist(df["Diagnosis"], bins=30, color='blue', edgecolor='black')

# Add labels
plt.title("Diagnosis Histogram")
plt.xlabel("Value")
plt.ylabel("Frequency")

# Distrubtion Of Featuers

count = 0
for col in df.columns:

  if count == 30:
    break
  sns.kdeplot(df[col], shade=True)
  plt.title('KDE Plot for ' + col + ' column')
  plt.show()
  count = count + 1

# Skewness & Kurtosis
count = 0
for col in df.columns:
  if count == 30:
    break
  print("Skewness for " , col , " column: ", df[col].skew())
  print("Kurtosis for" , col, "column: " , df[col].kurt())
  print("\n")
  count = count + 1

"""## B) Bivariate/Multivariate Analysis"""

# Drop object column
df_numeric = df.drop(columns=['Diagnosis'])

# Compute correlation matrix
corr_matrix = df_numeric.corr()

# Plot heatmap
plt.figure(figsize=(40, 20))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)

# Show plot
plt.title("Correlation Heatmap (Integer Columns Only)")
plt.show()

# Relationship between radius1 and texture1 column
sns.scatterplot(x='radius1', y='texture1', hue=df["Diagnosis"], data=df)
plt.title('radius1 vs texture1')
plt.show()

# Boxplot by Target

count = 0

for col in df.columns:
  if count == 30:
    break

  sns.boxplot(x='Diagnosis', y=col, data=df)
  plt.title('Boxplot Between Diagnosis and ' + col)
  plt.show()

  count = count + 1

"""# **4) Feature Engineering and Selection**"""

X = df.drop('Diagnosis', axis=1)
y = df['Diagnosis']

# Features Scaling, Normalization
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""## Remove High Correlated Features"""

# Use variance inflation factor to identify any significant multi-collinearity
def calc_vif(df):
    vif = pd.DataFrame()
    vif["variables"] = df_numeric.columns
    vif["VIF"] = [variance_inflation_factor(df_numeric.values, i) for i in range(df_numeric.shape[1])]
    return(vif)

calc_vif(df_numeric)

"""Remove High Correlated Features: (radius1, perimeter1, fractal_dimension1)

## Feature Importance using Mutual Information
"""

feature_names = [col for col in df.columns if col != "Diagnosis"]

# Encoding the Target
le = LabelEncoder()
y_encoded = le.fit_transform(y)

mi_scores = mutual_info_classif(X, y_encoded)
mi_scores = pd.Series(mi_scores, index=feature_names)
mi_scores.sort_values(ascending=False, inplace=True)

# Plot Information Gain
plt.figure(figsize=(10, 6))
mi_scores.plot(kind="bar", color="teal")
plt.title("Information Gain (Mutual Information)")
plt.xlabel("Features")
plt.ylabel("Mutual Information Score")
plt.show()

"""## Feature Selection using ANOVA"""

# ANOVA (F-test)
f_scores, _ = f_classif(X, y)  # ANOVA F-test
f_scores = pd.Series(f_scores, index=feature_names)
f_scores.sort_values(ascending=False, inplace=True)

# Plot ANOVA F-scores
plt.figure(figsize=(10, 6))
f_scores.plot(kind="bar", color="red")
plt.title("ANOVA F-scores")
plt.xlabel("Features")
plt.ylabel("F-score")
plt.show()

"""There is High relationship Between (perimeter3, cnocave_points1, radius3) features and the target. and the Relation between (texture2, smoothness2, symmetry2) is very low

## Feature Selection using Variance Threshold
"""

# Variance Threshold
variance_threshold = VarianceThreshold(threshold=0.1)  # Remove low-variance features
X_variance_selected = variance_threshold.fit_transform(X)

# Get selected features
selected_features = variance_threshold.get_support(indices=True)
print("Selected Features (Variance Threshold):", [feature_names[i] for i in selected_features])

# Remove High Correlated Features, low-variance features and low relationship features
df = df.drop(['radius1', 'perimeter1', 'fractal_dimension1'], axis=1)
df_numeric = df_numeric.drop(['radius1', 'perimeter1', 'fractal_dimension1'], axis=1)

# Step 4: Implementing a simplified version of the MLiT model
# In this example, we use Gaussian Mixture Models (GMM) as a basis for the mixture model
# and apply dimensionality reduction with PCA as a proxy for the linear transformations.

class MLiT:
    def __init__(self, n_components=2, n_dimensions=7):
        self.n_components = n_components
        self.n_dimensions = n_dimensions
        self.gmm = GaussianMixture(n_components=n_components)
        self.pca = None

    def fit(self, X):
        # Apply PCA to reduce dimensionality
        from sklearn.decomposition import PCA
        self.pca = PCA(n_components=self.n_dimensions)
        X_reduced = self.pca.fit_transform(X)

        # Fit a Gaussian Mixture Model on the reduced data
        self.gmm.fit(X_reduced)

        print(f"Explained variance by the first {self.n_dimensions} principal components: {np.sum(self.pca.explained_variance_ratio_):.4f}")
        print(f"Fitted GMM with {self.n_components} components.")

    def predict(self, X):
        # Transform the data using the fitted PCA
        X_reduced = self.pca.transform(X)

        # Use the GMM to predict the labels based on the transformed data
        return self.gmm.predict(X_reduced)

    def predict_proba(self, X):
        # Transform the data and compute probabilities using the GMM
        X_reduced = self.pca.transform(X)
        return self.gmm.predict_proba(X_reduced)

# Step 5: Instantiate and train the MLiT model
mlit_model = MLiT(n_components=2, n_dimensions=7)
mlit_model.fit(x_train)

# Step 6: Evaluate the model on the test set
y_pred = mlit_model.predict(x_test)

y_true_numeric = np.where(y_test == 'B', 0, 1)
accuracy = accuracy_score(y_true_numeric, y_pred)

print("\nClassification Report (MLiT Model):")
print(classification_report(y_true_numeric, y_pred))

print(f"Accuracy of the MLiT model: {accuracy:.4f}")

df.head().T

# # Step 7: Visualizing the results

y_train_numeric = np.where(y_train == 'B', 0, 1)
y_test_numeric = np.where(y_test == 'B', 0, 1)

# Transform the training and testing data using PCA for visualization
X_train_reduced = mlit_model.pca.transform(x_train)
X_test_reduced = mlit_model.pca.transform(x_test)

plt.figure(figsize=(8, 6))

# Plot the training data
plt.scatter(X_train_reduced[:, 0], X_train_reduced[:, 1], c=y_train_numeric, cmap='viridis', marker='o', label='Train')

# Plot the testing data
plt.scatter(X_test_reduced[:, 0], X_test_reduced[:, 1], c=y_test_numeric, cmap='coolwarm', marker='x', label='Test')

plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA Projection (First 2 Components) of the Breast Cancer Dataset')
plt.legend(loc='best')
plt.colorbar(label='Class')
plt.show()

# Step 8: Explainability (Interpretability)

# For explainability, we can examine the principal components that the model uses for dimensionality reduction
print("\nPrincipal Component Loadings (Important Features):")
pca_components_df = pd.DataFrame(mlit_model.pca.components_, columns=data.feature_names)
print(pca_components_df)

# Show the explained variance ratio to understand the importance of each component
print("\nExplained Variance Ratio by Each Principal Component:")
for i, var in enumerate(mlit_model.pca.explained_variance_ratio_):
    print(f"PC{i+1}: {var:.4f}")

# Plot the explained variance
plt.figure(figsize=(8, 6))
plt.bar(range(1, mlit_model.n_dimensions + 1), mlit_model.pca.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance of Each Principal Component')
plt.show()

# Step 9: Model Interpretability with SHAP

# Step 3: Fit the MLiT model
gmm = GaussianMixture(n_components=2)
gmm.fit(x_train)

explainer = shap.KernelExplainer(gmm.score_samples, x_train)  # Using the raw data

# Compute SHAP values for a set of test samples
shap_values = explainer.shap_values(x_test[:10])

# Summary plot: Visualizing the importance of each feature
shap.summary_plot(shap_values, x_test[:10], feature_names=data.feature_names)   # For class 1

from sklearn.model_selection import validation_curve

def plot_validation_curve(model, X_train, y_train, param_name, param_range):
    train_scores, test_scores = validation_curve(model, X_train, y_train, param_name=param_name, param_range=param_range, cv=5, n_jobs=-1)

    # Calculate the mean and standard deviation of training and testing scores
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    test_std = np.std(test_scores, axis=1)

    # Plot the validation curve
    plt.figure(figsize=(10, 6))
    plt.plot(param_range, train_mean, label="Training score", color="blue")
    plt.plot(param_range, test_mean, label="Validation score", color="green")
    plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, alpha=0.1, color="blue")
    plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, alpha=0.1, color="green")
    plt.title("Validation Curve")
    plt.xlabel(param_name)
    plt.ylabel("Score")
    plt.legend()
    plt.show()

# Hyperparameter to tune for validation curve (e.g., 'n_components' for GMM)
param_range = np.arange(1, 11)
plot_validation_curve(gmm, x_train, y_train, "n_components", np.arange(1, 11))

# Step 3: Plotting the Learning Curve

def plot_learning_curve(model, X_train, y_train):
    train_sizes, train_scores, test_scores = learning_curve(model, X_train, y_train, cv=5, n_jobs=-1,
                                                             train_sizes=np.linspace(0.1, 1.0, 5))
    # Calculate the mean and standard deviation of training and testing scores
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    test_std = np.std(test_scores, axis=1)

    # Plot the learning curve
    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, label="Training score", color="blue")
    plt.plot(train_sizes, test_mean, label="Cross-validation score", color="green")
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color="blue")
    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color="green")
    plt.title("Learning Curve")
    plt.xlabel("Training size")
    plt.ylabel("Score")
    plt.legend()
    plt.show()

# Fit the GMM model
gmm = GaussianMixture(n_components=2)
plot_learning_curve(gmm, x_train, y_train)

# Step 3: LIME Explainer

gmm = GaussianMixture(n_components=2)
gmm.fit(X_train_reduced)

def predict_proba(X):
    return gmm.predict_proba(X)

# Create the LIME tabular explainer
explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=x_train,
    feature_names=data.feature_names,
    class_names=["Malignant", "Benign"],
    mode="classification"
)

instance_idx = 5
instance = x_test[5]

# Explain the model's prediction for this instance
explanation = explainer.explain_instance(instance, predict_proba)

# Step 5: Plot the explanation
explanation.show_in_notebook(show_table=True, show_all=False)  # Show in notebook