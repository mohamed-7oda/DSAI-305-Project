# -*- coding: utf-8 -*-
"""Amin-20220219(Parzen combined with decision trees).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17_fJqNNLWFR27tS5a7HMA-qXa0Eu8Zob

[Paper 2 Link](https://sciendo-parsed.s3.eu-central-1.amazonaws.com/647387ff4e662f30ba541057/10.2478_slgr-2013-0045.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIA6AP2G7AKP2BFFZZU%2F20250503%2Feu-central-1%2Fs3%2Faws4_request&X-Amz-Date=20250503T170051Z&X-Amz-Expires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEFkaDGV1LWNlbnRyYWwtMSJHMEUCIQChLRp8J8Ja0V2j8fbwS4%2FqGR%2Fnr0JdL%2FqESJZpktklkQIgZufNUy4%2Bd8xPPqWKCHLjBW45HeicuDLvc%2BumIP%2FAGjIqxgUI8v%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARACGgw5NjMxMzQyODk5NDAiDEUXmWkgNtE38y9twyqaBT6pz6gfhDCcWSn4OBuZPdDvW9IB9pnHpcpnQdgGVUBFae1fDw5kiP4dqkDwR0YPfbEP%2BHGsw7NbV8X4zm1JfzzhNFPgXVTPIZtQnUO4%2B1nUSZubpZ5RICkH7TpvuFUDDHmMJpKLOYuZw6ZvaGXOmqgYqL%2F3z3eDsobeDpI9eTvyzld99KJy13alzM4o1KIlB9inX1tWClr%2FDKOKSbadXjkt%2BRSnQWVxnWPEmgFZQFnIJZCEVQ3wEB%2Bnb4f1lgcae4lV5UKpfC491DUXmZLbog4tVyplpEfkBFl6Z5smNDj%2FCfVFpFsUBl6Y5KJbyTVOpa4%2Fs8%2BqGv9PKOrc7VcqxTqznzMYSPVkQNq608jfelphOULvvrec9mJ9PBiS5hCaRBxiiEw3nTv6sLuDlQnXvSpWtGg0mg7JwEg9qOAdPwukdyijE5H8c%2BuVK6SvTI4tf6I9fpQO9U7%2B%2BIgbCgReJdyLmLjGSyVPYjwV0S5tzCfGsKa4l0MXXuM1HFXpzWmHw%2BPfUndINQMBawY%2FfYzTd3s%2Bs5SAF3Cc5Yf%2FBL3FZwH9tJXjAi3A5icZGuu1YBagNMt76tXHh0d4C%2BY9vum8ey0hqpRfSdXZsR5yq7TKPnFkBXblhhWy2OnRHqAZOooy2KSxGgN9qVRgUH11P4xGVvPzsZtYP3TarTv%2BWkV2CTBTTAGjf21w85lgyPmVH5eY4%2F6YBYU1LP5m%2BMj5akWSVnOupdG2kUYxCxdK7qnxK02gbx6g4Kq40I83KagI7Um8t%2F0KMPyctml8nC9ildPxn6mo%2F5ErSKk307vQbl2pcLOyWzcScAt5N%2FJFBxNZFFLPzSGYksUZGyqT7PD4zoH0ICqi1MazbEvC286Bx%2BQbNAU9CsTaFWvMrQsZETCciNnABjqxAV%2Bl5SXAcKAIDtOGJDEIa6WuNMUrwZ4YGUN5QEXqiXIXtLhH9wjuzWbsAFj9alU4gaOgSoqzuUq0yCCUla0BuM6dlueeR0tLZi1BQrOOHBuNKZ8shh%2BSJZ%2B9UaTHICTo0tzDJeJy7WCxQU0qItzVTnR%2BFTeKTeQSsH43bPwdICs9Z4fYADHQfgXOHzG%2B4sylSK5rnWdxd%2FKmoqYd1WLGIPJd9WMvdzNW7KLIXR54MA4u5g%3D%3D&X-Amz-Signature=07fc1e5d3ee4b9e1d08b69e2350c31ccba1605837a0e02cecd1f590adc801e56&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObject)



Model: Bayesian classifiers (like Parzen) combined with decision trees
"""

!pip install ucimlrepo

!pip install scikit-learn matplotlib seaborn shap lime

x

"""# **1) Data Overview**"""

df.head()

# Number of Rows and Number of Columns
Rows, Cols = df.shape
print("Number of Row in Data = ", Rows)
print("Number of Columns in Data = ", Cols)

# Columns Names
df.columns

df.info()

# Verify data types
df.dtypes

"""# **2) Preprocessing & Cleaning**"""

# Handling Null Values
df.isnull().sum()

# Check Duplicates
print(df.duplicated().sum())

"""## **Handling Outliers**"""

for col in df.columns:
  if ((df[col].dtype) == "int64") or ((df[col].dtype) == "float64"):
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    # Define lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Calculate mean (excluding outliers)
    mean_value = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)][col].mean()

    # Replace outliers with mean
    df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), mean_value, df[col])

count = 0

for col in df.columns:
  if count == 30:
    break
  # Create boxplot
  plt.boxplot(df[col])

  # Add labels
  plt.title("Boxplot for " + col + " column")
  plt.ylabel("Values")

  # Show plot
  plt.show()

  count = count + 1

"""# **3) EDA**

## A) Univariate Analysis
"""

# Statistics
df.describe()

# Target Value Counts
target_df = pd.Series(df["Diagnosis"], name='target')
target_df.value_counts(normalize=True)

# Distrubtion Of Featuers

for col in df.columns:
  if ((df[col].dtype) == "int64") or ((df[col].dtype) == "float64"):
    # Plot histogram
    plt.hist(df[col], bins=30, color='blue', edgecolor='black')

    # Add labels
    plt.title("Histogram for " + col + " column")
    plt.xlabel("Value")
    plt.ylabel("Frequency")

    # Show plot
    plt.show()

# Target Value Distrubtion

# Plot histogram
plt.hist(df["Diagnosis"], bins=30, color='blue', edgecolor='black')

# Add labels
plt.title("Diagnosis Histogram")
plt.xlabel("Value")
plt.ylabel("Frequency")

# Distrubtion Of Featuers

count = 0
for col in df.columns:

  if count == 30:
    break
  sns.kdeplot(df[col], shade=True)
  plt.title('KDE Plot for ' + col + ' column')
  plt.show()
  count = count + 1

# Skewness & Kurtosis
count = 0
for col in df.columns:
  if count == 30:
    break
  print("Skewness for " , col , " column: ", df[col].skew())
  print("Kurtosis for" , col, "column: " , df[col].kurt())
  print("\n")
  count = count + 1

"""## B) Bivariate/Multivariate Analysis"""

# Drop object column
df_numeric = df.drop(columns=['Diagnosis'])

# Compute correlation matrix
corr_matrix = df_numeric.corr()

# Plot heatmap
plt.figure(figsize=(40, 20))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)

# Show plot
plt.title("Correlation Heatmap (Integer Columns Only)")
plt.show()

# Relationship between radius1 and texture1 column
sns.scatterplot(x='radius1', y='texture1', hue=df["Diagnosis"], data=df)
plt.title('radius1 vs texture1')
plt.show()

# Boxplot by Target

count = 0

for col in df.columns:
  if count == 30:
    break

  sns.boxplot(x='Diagnosis', y=col, data=df)
  plt.title('Boxplot Between Diagnosis and ' + col)
  plt.show()

  count = count + 1

"""# **4) Feature Engineering and Selection**"""

X = df.drop('Diagnosis', axis=1)
y = df['Diagnosis']

# Features Scaling, Normalization
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

"""## Remove High Correlated Features"""

# Use variance inflation factor to identify any significant multi-collinearity
def calc_vif(df):
    vif = pd.DataFrame()
    vif["variables"] = df_numeric.columns
    vif["VIF"] = [variance_inflation_factor(df_numeric.values, i) for i in range(df_numeric.shape[1])]
    return(vif)

calc_vif(df_numeric)

"""Remove High Correlated Features: (radius1, perimeter1, fractal_dimension1)

## Feature Importance using Mutual Information
"""

feature_names = [col for col in df.columns if col != "Diagnosis"]

# Encoding the Target
le = LabelEncoder()
y_encoded = le.fit_transform(y)

mi_scores = mutual_info_classif(X, y_encoded)
mi_scores = pd.Series(mi_scores, index=feature_names)
mi_scores.sort_values(ascending=False, inplace=True)

# Plot Information Gain
plt.figure(figsize=(10, 6))
mi_scores.plot(kind="bar", color="teal")
plt.title("Information Gain (Mutual Information)")
plt.xlabel("Features")
plt.ylabel("Mutual Information Score")
plt.show()

"""## Feature Selection using ANOVA"""

# ANOVA (F-test)
f_scores, _ = f_classif(X, y)  # ANOVA F-test
f_scores = pd.Series(f_scores, index=feature_names)
f_scores.sort_values(ascending=False, inplace=True)

# Plot ANOVA F-scores
plt.figure(figsize=(10, 6))
f_scores.plot(kind="bar", color="red")
plt.title("ANOVA F-scores")
plt.xlabel("Features")
plt.ylabel("F-score")
plt.show()

"""There is High relationship Between (perimeter3, cnocave_points1, radius3) features and the target. and the Relation between (texture2, smoothness2, symmetry2) is very low

## Feature Selection using Variance Threshold
"""

# Variance Threshold
variance_threshold = VarianceThreshold(threshold=0.1)  # Remove low-variance features
X_variance_selected = variance_threshold.fit_transform(X)

# Get selected features
selected_features = variance_threshold.get_support(indices=True)
print("Selected Features (Variance Threshold):", [feature_names[i] for i in selected_features])

# Remove High Correlated Features, low-variance features and low relationship features
df = df.drop(['radius1', 'perimeter1', 'fractal_dimension1'], axis=1)
df_numeric = df_numeric.drop(['radius1', 'perimeter1', 'fractal_dimension1'], axis=1)

"""##**model 2 implementation**"""

dt_classifier = DecisionTreeClassifier(random_state=42)

parzen_classifier = KNeighborsClassifier(n_neighbors=5)

# 3. Ensemble Methods: Bagging and Boosting
# Bagging with Decision Trees
bagging_classifier = BaggingClassifier(dt_classifier, n_estimators=50, random_state=42)

# Boosting with Decision Trees
boosting_classifier = AdaBoostClassifier(dt_classifier, n_estimators=50, random_state=42)

# Train and Evaluate the models

dt_classifier.fit(X_train, y_train)
parzen_classifier.fit(X_train, y_train)
bagging_classifier.fit(X_train, y_train)
boosting_classifier.fit(X_train, y_train)

# Make predictions on the test set
y_pred_dt = dt_classifier.predict(X_test)
y_pred_parzen = parzen_classifier.predict(X_test)
y_pred_bagging = bagging_classifier.predict(X_test)
y_pred_boosting = boosting_classifier.predict(X_test)

# 5. Evaluate Model Performance
def print_classification_report(y_test, y_pred, model_name):
    print(f"Classification Report for {model_name}:")
    print(classification_report(y_test, y_pred))
    print(f"Accuracy: {accuracy_score(y_test, y_pred)}\n")

# Print reports for each model
print_classification_report(y_test, y_pred_dt, "Decision Tree")
print_classification_report(y_test, y_pred_parzen, "Parzen Classifier (KNN)")
print_classification_report(y_test, y_pred_bagging, "Bagging (DT)")
print_classification_report(y_test, y_pred_boosting, "Boosting (DT)")

def cross_val_score_plot(classifier, name):
    scores = cross_val_score(classifier, X, y, cv=5, scoring='accuracy')
    print(f"Cross-validation accuracy for {name}: {scores.mean()} Â± {scores.std()}")
    plt.plot(range(1, 6), scores, label=name)

# cross-validation scores for all models
plt.figure(figsize=(10, 6))
cross_val_score_plot(dt_classifier, "Decision Tree")
cross_val_score_plot(parzen_classifier, "Parzen Classifier (KNN)")
cross_val_score_plot(bagging_classifier, "Bagging (DT)")
cross_val_score_plot(boosting_classifier, "Boosting (DT)")
plt.title('Cross-Validation Scores')
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.legend()

# visualize the performance using learning curves

errors = []
for n_estimators in range(1, 51):
    boosting_classifier.set_params(n_estimators=n_estimators)
    boosting_classifier.fit(X_train, y_train)
    error = 1 - boosting_classifier.score(X_test, y_test)
    errors.append(error)

plt.plot(range(1, 51), errors, label="Boosting Error Rate")
plt.title("Learning Curve for Boosting Classifier")
plt.xlabel("Number of Estimators")
plt.ylabel("Error Rate")

"""## **SHAP Explainability for Decision Tree, Bagging, and Boosting**"""

# Decision Tree

explainer_dt = shap.TreeExplainer(dt_classifier)
shap_values_dt = explainer_dt.shap_values(X_test)

# SHAP summary plot for Decision Tree
shap.summary_plot(shap_values_dt, X_test, feature_names=df.columns)

# SHAP for Bagging using KernelExplainer
explainer_bagging = shap.KernelExplainer(bagging_classifier.predict_proba, shap.sample(X_train, 50))
shap_values_bagging = explainer_bagging.shap_values(X_test)

# SHAP summary plot for Bagging
shap.summary_plot(shap_values_bagging, X_test, feature_names=df.columns)

# SHAP for Boosting using KernelExplainer
explainer_boosting = shap.KernelExplainer(boosting_classifier.predict_proba, shap.sample(X_train, 50))
shap_values_boosting = explainer_boosting.shap_values(X_test)

# SHAP summary plot for Boosting
shap.summary_plot(shap_values_boosting, X_test, feature_names=df.columns)

"""## **LIME Explainability**"""

explainer_lime = LimeTabularExplainer(X_train,
                                      training_labels=y_train,
                                      mode="classification",
                                      feature_names=data.feature_names,
                                      class_names=["Malignant", "Benign"])

i = 15
exp_dt = explainer_lime.explain_instance(X_test[i], dt_classifier.predict_proba)

# Plot the LIME explanation for Decision Tree
exp_dt.as_pyplot_figure()
plt.show()

# LIME Explainability for Bagging
exp_bagging = explainer_lime.explain_instance(X_test[i], bagging_classifier.predict_proba)

exp_bagging.as_pyplot_figure()
plt.show()

# LIME Explainability for Boosting
exp_boosting = explainer_lime.explain_instance(X_test[i], boosting_classifier.predict_proba)

exp_boosting.as_pyplot_figure()
plt.show()

"""## **Feature Importance (For Decision Tree, Bagging, and Boosting)**"""

# For Decision Tree
print(f"Feature Importances for Decision Tree:\n{dt_classifier.feature_importances_}\n")

# For Bagging
bagging_importances = np.mean([tree.feature_importances_ for tree in bagging_classifier.estimators_], axis=0)
print(f"Feature Importances for Bagging:\n{bagging_importances}\n")

# For Boosting
boosting_importances = boosting_classifier.feature_importances_
print(f"Feature Importances for Boosting:\n{boosting_importances}\n")

# Plotting the feature importances
features = data.feature_names
plt.figure(figsize=(12, 6))
plt.barh(features, dt_classifier.feature_importances_)
plt.title("Feature Importance for Decision Tree")
plt.show()

plt.figure(figsize=(12, 6))
plt.barh(features, bagging_importances)
plt.title("Feature Importance for Bagging")
plt.show()

plt.figure(figsize=(12, 6))
plt.barh(features, boosting_importances)
plt.title("Feature Importance for Boosting")
plt.show()

"""## **Curves**"""

# 1. Learning Curve
def plot_learning_curve(model, X_train, y_train, cv=5):
    train_sizes, train_scores, val_scores = learning_curve(model, X_train, y_train, cv=cv, n_jobs=-1)
    train_mean = np.mean(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)

    plt.figure(figsize=(10, 6))
    plt.plot(train_sizes, train_mean, label="Training score", color="blue")
    plt.plot(train_sizes, val_mean, label="Validation score", color="red")
    plt.xlabel("Training Set Size")
    plt.ylabel("Accuracy")
    plt.title(f"Learning Curve for {model.__class__.__name__}")
    plt.legend(loc="best")
    plt.grid(True)
    plt.show()

    # 2. Validation Curve
def plot_validation_curve(model, X_train, y_train, param_name, param_range):
    train_scores, val_scores = validation_curve(model, X_train, y_train, param_name=param_name,
                                                param_range=param_range, cv=5, n_jobs=-1)

    train_mean = np.mean(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)

    plt.figure(figsize=(10, 6))
    plt.plot(param_range, train_mean, label="Training score", color="blue")
    plt.plot(param_range, val_mean, label="Validation score", color="red")
    plt.xlabel(param_name)
    plt.ylabel("Accuracy")
    plt.title(f"Validation Curve for {model.__class__.__name__}")
    plt.legend(loc="best")
    plt.grid(True)
    plt.show()

# Plot learning curve
plot_learning_curve(dt_classifier, X_train, y_train)
plot_learning_curve(bagging_classifier, X_train, y_train)
plot_learning_curve(boosting_classifier, X_train, y_train)

# Plot validation curve for Boosting (parameter n_estimators)
param_range = np.arange(1, 101, 5)
plot_validation_curve(boosting_classifier, X_train, y_train, param_name="n_estimators", param_range=param_range)